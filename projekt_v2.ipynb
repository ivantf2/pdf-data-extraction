{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb67d2b9",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661cd1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d75ebf",
   "metadata": {},
   "source": [
    "#### Funkcije za procesiranje, normalizaciju podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca987e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broj PDF-ova: 110\n"
     ]
    }
   ],
   "source": [
    "# setup direktorija koji se koriste\n",
    "PROJECT_DIR = Path(\".\").resolve()\n",
    "PDF_DIR = PROJECT_DIR / \"pdfs\"\n",
    "OUT_DIR = PROJECT_DIR / \"out\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "CACHE_DIR = OUT_DIR / \"cache\"\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "pdf_paths = sorted(PDF_DIR.glob(\"*.pdf\"))\n",
    "print(\"Broj PDF-ova:\", len(pdf_paths))\n",
    "\n",
    "# pomocne funkcije za normaliziranje teksta \n",
    "def normalize_text(s: Any) -> str:\n",
    "    \"\"\"Osigurava pretvaranje inputa u normalizirani string.\"\"\"\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = str(s)\n",
    "    # zamjena ligatura i uklanjanje suvisnih razmaka i novih redaka\n",
    "    s = s.replace(\"ﬁ\", \"fi\").replace(\"ﬂ\", \"fl\").replace(\"ﬀ\", \"ff\").replace(\"ﬃ\", \"ffi\").replace(\"ﬄ\", \"ffl\")\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def remove_reference_noise(text: str) -> str:\n",
    "    \"\"\"Uklanja URL-ove i web adrese iz teksta (šum u referencama).\"\"\"\n",
    "    text = re.sub(r\"http[s]?://\\S+\", \"\", text)\n",
    "    text = re.sub(r\"www\\.\\S+\", \"\", text)\n",
    "    return normalize_text(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f1a524",
   "metadata": {},
   "source": [
    "#### Procesiranje autora i naslova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globalni markeri(bitne rijeci) za zaustavljane \n",
    "_STOP_MARKERS = [\n",
    "    \"abstract\", \"introduction\", \"keywords\", \"key words\",\n",
    "    \"article\", \"open\", \"received\", \"accepted\", \"published\",\n",
    "    \"correspondence\", \"email\", \"doi\", \"journal\", \"npj\",\n",
    "]\n",
    "_SMALL_NAME_WORDS = {\"van\", \"von\", \"de\", \"der\", \"da\", \"di\", \"del\", \"la\", \"le\", \"du\", \"of\", \"and\"}\n",
    "\n",
    "def looks_like_affiliation(line: str) -> bool:\n",
    "    \"\"\"Provjerava je li linija vjerojatno afiliacija (sadrži ključne riječi institucija).\"\"\"\n",
    "    return bool(re.search(r\"\\b(University|Department|Institute|Laboratory|Centre|Center|Present address|Address)\\b\", \n",
    "                          line, flags=re.IGNORECASE))\n",
    "\n",
    "def _looks_like_body_text(line: str) -> bool:\n",
    "    \"\"\"Heuristika za prepoznavanje početka glavnog teksta (normalnih rečenica) radi prekida extrakcije autora.\"\"\"\n",
    "    if not line:\n",
    "        return False\n",
    "    low = line.lower()\n",
    "    # ako linija sadrži ključne riječi (markere) => tretiraj kao body\n",
    "    if any(marker in low for marker in _STOP_MARKERS):\n",
    "        return True\n",
    "    # ako linija izgleda kao normalna recenica (mnogi mali znakovi + točka ili zarez) => body\n",
    "    letters = [c for c in line if c.isalpha()]\n",
    "    lower_ratio = sum(c.islower() for c in letters) / max(1, len(letters)) if letters else 0\n",
    "    if lower_ratio > 0.55 and ((\".\" in line) or (\",\" in line)) and len(line) > 80:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def extract_title_from_page(first_page_text: str) -> str:\n",
    "    \"\"\"Izvlači naslov članka sa prve stranice.\"\"\"\n",
    "    if not first_page_text:\n",
    "        return \"\"\n",
    "    lines = [ln.strip() for ln in first_page_text.splitlines() if ln.strip()]\n",
    "    # preskoci linije \"ARTICLE\" / \"OPEN\" ako postoje\n",
    "    start_idx = 0\n",
    "    for k, ln in enumerate(lines[:80]):\n",
    "        up = ln.upper()\n",
    "        if up == \"ARTICLE\" or up == \"OPEN\":\n",
    "            start_idx = k + 1\n",
    "    title_lines = []\n",
    "    for ln in lines[start_idx:start_idx + 30]:\n",
    "        low = ln.lower()\n",
    "        # prekini ako dodemo do meta podataka ili afiliacija\n",
    "        if looks_like_affiliation(ln) or low.startswith(\"npj \") or low.startswith(\"published\") or low.startswith(\"doi\") or low.startswith(\"received\") or low.startswith(\"accepted\"):\n",
    "            break\n",
    "        if \"@\" in ln:\n",
    "            break\n",
    "        # ako je linija prepoznata kao linija autora i vec imamo dio naslova, prekini (naslov je zavrsen)\n",
    "        if (re.search(r\"\\d\", ln) or \" and \" in low or \",\" in ln) and title_lines:\n",
    "            # dodatna provjera: ako linija sadrzi tipične rijeci recenice (npr. \"we\", \"have\"), vjerojatno je to dio sazetka, ne lista autora\n",
    "            if not re.search(r\"\\b(we|have|has|using|show|are|is)\\b\", low):\n",
    "                break\n",
    "        # dodaj liniju u naslov\n",
    "        title_lines.append(re.sub(r\"\\s+\", \" \", ln).strip())\n",
    "        if len(title_lines) >= 5:\n",
    "            break\n",
    "    title = \" \".join(title_lines).strip()\n",
    "    # ocisti potencijalno zalijepljeno ime autora na kraju naslova\n",
    "    m = re.match(r\"^(.*?)(?:\\s+[A-Z][a-zA-Z.\\-’']+\\s+[A-Z][a-zA-Z.\\-’']+)$\", title)\n",
    "    if m and len(title) > 40:\n",
    "        title = m.group(1).strip()\n",
    "    return title\n",
    "\n",
    "def extract_authors_from_page(first_page_text: str, title: str) -> str:\n",
    "    \"\"\"Izvlači imena autora sa prve stranice (ispod naslova), robustno za višelinijske popise autora.\"\"\"\n",
    "    lines = [re.sub(r\"\\s+\", \" \", ln).strip() for ln in first_page_text.splitlines()]\n",
    "    lines = [ln for ln in lines if ln]\n",
    "    if not lines:\n",
    "        return \"\"\n",
    "    # pronadi pocetak nakon naslova\n",
    "    start_idx = 0\n",
    "    title_clean = re.sub(r\"\\s+\", \" \", title or \"\").strip()\n",
    "    if title_clean:\n",
    "        for idx, ln in enumerate(lines[:80]):\n",
    "            if title_clean.lower() in ln.lower():\n",
    "                start_idx = idx + 1\n",
    "                break\n",
    "    author_lines = []\n",
    "    for ln in lines[start_idx:start_idx + 12]:\n",
    "        low = ln.lower().strip()\n",
    "        # preskoci ako je oznaka clanka ili slican marker\n",
    "        if low == \"article\" or low == \"open\":\n",
    "            continue\n",
    "        # prekini na afiliacijama ili meta podacima (casopis, doi, itd.)\n",
    "        if looks_like_affiliation(ln) or low.startswith(\"npj \") or low.startswith(\"doi\"):\n",
    "            break\n",
    "        if \"introduction\" in low or low.startswith(\"abstract\"):\n",
    "            break\n",
    "        if _looks_like_body_text(ln):\n",
    "            break\n",
    "        # Obrada linija s autorima\n",
    "        if not author_lines:\n",
    "            # prva linija s autorima treba imati naznake (brojeve, zareze, \"and\", ✉)\n",
    "            if re.search(r\"\\d\", ln) or \",\" in ln or \" and \" in low or \"✉\" in ln:\n",
    "                if not ln.rstrip().endswith(\".\") and len(re.findall(r\"\\b[A-Z][a-zA-ZÀ-ÖØ-öø-ÿ’'\\-]+\\b\", ln)) >= 2:\n",
    "                    author_lines.append(ln)\n",
    "        else:\n",
    "            # dodaj sljedeće linije autora ako ne izgledaju kao kraj\n",
    "            if ln.lower().startswith(\"and \"):\n",
    "                author_lines.append(ln)\n",
    "            elif not ln.rstrip().endswith(\".\"):\n",
    "                author_lines.append(ln)\n",
    "            else:\n",
    "                break\n",
    "    raw_authors = \" \".join(author_lines).strip()\n",
    "    if not raw_authors:\n",
    "        return \"\"\n",
    "    # ukloni email adrese i footnote znakove/brojeve\n",
    "    raw_authors = re.sub(r\"\\S+@\\S+\", \" \", raw_authors)\n",
    "    raw_authors = raw_authors.replace(\"✉\", \" \")\n",
    "    raw_authors = raw_authors.replace(\"†\", \" \").replace(\"‡\", \" \").replace(\"*\", \" \")\n",
    "    raw_authors = re.sub(r\"\\d+\", \" \", raw_authors)\n",
    "    raw_authors = re.sub(r\"\\s+\", \" \", raw_authors).strip()\n",
    "    # podijeli autore po zarezima, \";\" ili \" and \"\n",
    "    parts = re.split(r\",|;|\\band\\b\", raw_authors)\n",
    "    parts = [p.strip() for p in parts if p.strip()]\n",
    "    # ocisti svaki segment imena i filtriraj nepodobne\n",
    "    cleaned_authors = []\n",
    "    for tok in parts:\n",
    "        # ukloni potencijalne ostatke footnota i visak razmaka\n",
    "        tok = re.sub(r\"[(){}\\[\\]]\", \"\", tok).strip()\n",
    "        if len(tok) > 80 or len(tok.split()) < 2:\n",
    "            continue\n",
    "        # provjeri da li se svaki dio imena ispravno piše (pocetno slovo veliko osim dozvoljenih malih rijeci)\n",
    "        words = tok.split()\n",
    "        alpha_words = [w for w in words if any(ch.isalpha() for ch in w)]\n",
    "        if not alpha_words:\n",
    "            continue\n",
    "        bad = 0\n",
    "        for w in alpha_words:\n",
    "            w_clean = re.sub(r\"[^A-Za-zÀ-ÖØ-öø-ÿ’'\\-]\", \"\", w)\n",
    "            if not w_clean:\n",
    "                continue\n",
    "            if w_clean.lower() in _SMALL_NAME_WORDS:\n",
    "                continue\n",
    "            if not w_clean[0].isupper():\n",
    "                bad += 1\n",
    "        if bad >= 2:\n",
    "            continue\n",
    "        cleaned_authors.append(tok)\n",
    "    # zadrzi unikatna imena redom pojavljivanja, najvise 25 autora\n",
    "    seen = set()\n",
    "    unique_authors = []\n",
    "    for name in cleaned_authors:\n",
    "        key = name.lower()\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            unique_authors.append(name)\n",
    "    return \"; \".join(unique_authors[:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef74a7",
   "metadata": {},
   "source": [
    "#### Batch procesiranje svih pdf-ova u /pdfs folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd303062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obrađeno 10/110\n",
      "Obrađeno 20/110\n",
      "Obrađeno 30/110\n",
      "Obrađeno 40/110\n",
      "Obrađeno 50/110\n",
      "Obrađeno 60/110\n",
      "Obrađeno 70/110\n",
      "Obrađeno 80/110\n",
      "Obrađeno 90/110\n",
      "Obrađeno 100/110\n",
      "Obrađeno 110/110\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "# fallback\n",
    "if \"choose_page_limits\" not in globals():\n",
    "    def choose_page_limits(pdf_path: Path) -> tuple[int, int]:\n",
    "        meta_pages = 2\n",
    "        size_mb = pdf_path.stat().st_size / (1024 * 1024)\n",
    "        if size_mb >= 25:\n",
    "            content_pages = 8\n",
    "        elif size_mb >= 10:\n",
    "            content_pages = 12\n",
    "        else:\n",
    "            content_pages = 15\n",
    "        return meta_pages, content_pages\n",
    "\n",
    "if \"guess_year\" not in globals():\n",
    "    def guess_year(text: str) -> str:\n",
    "        m = re.search(r\"\\(\\s*(19\\d{2}|20\\d{2})\\s*\\)\", text)\n",
    "        if m:\n",
    "            y = m.group(1)\n",
    "            window = text[max(0, m.start()-80):m.end()+80].lower()\n",
    "            if \"npj\" in window or \"©\" in window or \"author\" in window or \"published\" in window:\n",
    "                return y\n",
    "\n",
    "        m = re.search(r\"©.*\\b(19\\d{2}|20\\d{2})\\b\", text)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "\n",
    "        m = re.search(r\"(Received|Accepted|Published)[^\\n]*\\b(19\\d{2}|20\\d{2})\\b\", text, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            return m.group(2)\n",
    "\n",
    "        return \"\"\n",
    "\n",
    "# brza ekstrakcija\n",
    "def extract_pages_text_fast(pdf_path: Path, max_pages: int) -> list[str]:\n",
    "    out = []\n",
    "    doc = fitz.open(str(pdf_path))\n",
    "    limit = min(doc.page_count, max_pages)\n",
    "    for i in range(limit):\n",
    "        out.append(normalize_text(doc.load_page(i).get_text(\"text\")))\n",
    "    doc.close()\n",
    "    return out\n",
    "\n",
    "records = []\n",
    "total = len(pdf_paths)\n",
    "\n",
    "for i, pdf_path in enumerate(pdf_paths, start=1):\n",
    "    try:\n",
    "        meta_pages, content_pages = choose_page_limits(pdf_path)\n",
    "\n",
    "        # meta podaci\n",
    "        meta_pages_text = extract_pages_text_fast(pdf_path, max_pages=meta_pages)\n",
    "        first_page_text = meta_pages_text[0] if meta_pages_text else \"\"\n",
    "        head_text = \"\\n\\n\".join(meta_pages_text)\n",
    "        text_head = remove_reference_noise(head_text)\n",
    "\n",
    "        # content kolona\n",
    "        content_pages_text = extract_pages_text_fast(pdf_path, max_pages=content_pages)\n",
    "        content_text = remove_reference_noise(\"\\n\\n\".join([t for t in content_pages_text if t]))\n",
    "\n",
    "        # broj stranica kolona\n",
    "        with fitz.open(str(pdf_path)) as doc:\n",
    "            num_pages = doc.page_count\n",
    "\n",
    "        # title + authors + year kolone\n",
    "        title = extract_title_from_page(first_page_text)\n",
    "        authors_raw = extract_authors_from_page(text_head, title)  # may be \"\"\n",
    "        year = guess_year(head_text)\n",
    "\n",
    "        # abstract + content razdvojeno\n",
    "        abstract_text = \"\"\n",
    "        content_main = content_text\n",
    "        m_intro = re.search(r\"\\nINTRODUCTION\\b\", content_text, flags=re.IGNORECASE)\n",
    "        if m_intro:\n",
    "            intro_index = m_intro.start()\n",
    "            abstract_text = content_text[:intro_index].strip()\n",
    "            abstract_text = re.sub(r\"(?im)^(ARTICLE|OPEN)\\s*$\", \"\", abstract_text)\n",
    "            abstract_text = re.sub(r\"(?im)^npj.*$\", \"\", abstract_text)\n",
    "            abstract_text = re.sub(r\"(?im)^Published.*$\", \"\", abstract_text)\n",
    "            abstract_text = re.sub(r\"\\n{2,}\", \"\\n\", abstract_text).strip()\n",
    "            content_main = content_text[intro_index:].strip()\n",
    "\n",
    "        if abstract_text and len(abstract_text) < 200:\n",
    "            abstract_text = \"\"\n",
    "\n",
    "        has_tables = bool(re.search(r\"\\b(Table|Tablica)\\b\", content_text, flags=re.IGNORECASE))\n",
    "\n",
    "        issues = []\n",
    "        if not title:\n",
    "            issues.append(\"Nije pronađen naslov.\")\n",
    "        if len(content_text) < 3000:\n",
    "            issues.append(\"Malo izvučenog teksta (mogući skenirani PDF).\")\n",
    "        if \"�\" in content_text:\n",
    "            issues.append(\"Neispravni znakovi (enkodiranje).\")\n",
    "        issues.append(f\"Sadržaj izvučen iz prvih {content_pages} stranica radi performansi.\")\n",
    "\n",
    "        # uzimanje dijela cijelog sadrzaja (prvih 4000 znakova) kao 'content' kolona\n",
    "        content_snippet = content_main.strip()\n",
    "        if len(content_snippet) > 4000:\n",
    "            content_snippet = content_snippet[:4000] + \"\\n\\n[TRUNCATED]\"\n",
    "\n",
    "        records.append({\n",
    "            \"file_name\": pdf_path.name,\n",
    "            \"title\": title,\n",
    "            \"authors_raw\": authors_raw,\n",
    "            \"year\": year,\n",
    "            \"abstract\": abstract_text,\n",
    "            \"content\": content_snippet,\n",
    "            \"num_pages\": num_pages,\n",
    "            \"has_tables\": has_tables,\n",
    "            \"extraction_issues\": \" \".join(issues),\n",
    "        })\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Obrađeno {i}/{total}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        records.append({\n",
    "            \"file_name\": pdf_path.name,\n",
    "            \"title\": \"\",\n",
    "            \"authors_raw\": \"\",\n",
    "            \"year\": \"\",\n",
    "            \"abstract\": \"\",\n",
    "            \"content\": \"\",\n",
    "            \"num_pages\": 0,\n",
    "            \"has_tables\": False,\n",
    "            \"extraction_issues\": f\"Greška pri obradi PDF-a: {type(e).__name__}: {e}\",\n",
    "        })\n",
    "        print(f\"[ERROR] {pdf_path.name}: {type(e).__name__}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e91a9",
   "metadata": {},
   "source": [
    "#### Export u JSON, CSV, XML, Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spremljeno u out/: results.csv, results.json, results.xml, results.parquet\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = Path(\"out\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame(records).copy()\n",
    "\n",
    "# --- year se pretvara iz 2020.0 u 2020 ---\n",
    "if \"year\" in df.columns:\n",
    "    df[\"year\"] = df[\"year\"].fillna(\"\").astype(str).str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "\n",
    "# --- 1) CSV (samo authors_raw) ---\n",
    "df.to_csv(OUT_DIR / \"results.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# --- 2) JSON (authors lista, bez authors_raw) ---\n",
    "df_json = df.copy()\n",
    "if \"authors_raw\" in df_json.columns:\n",
    "    df_json[\"authors\"] = df_json[\"authors_raw\"].fillna(\"\").map(\n",
    "        lambda s: [a.strip() for a in str(s).split(\";\") if a.strip()]\n",
    "    )\n",
    "    df_json = df_json.drop(columns=[\"authors_raw\"])\n",
    "else:\n",
    "    df_json[\"authors\"] = [[] for _ in range(len(df_json))]\n",
    "\n",
    "with open(OUT_DIR / \"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(df_json.to_dict(orient=\"records\"), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# --- 3) XML (očisti kontrolne znakove) ---\n",
    "def safe_xml_cell(x):\n",
    "    s = \"\" if x is None else str(x)\n",
    "    return \"\".join(ch for ch in s if ch in \"\\t\\n\\r\" or ord(ch) >= 32)\n",
    "\n",
    "df_xml = df.copy()\n",
    "df_xml = df_xml.apply(lambda col: col.map(safe_xml_cell))\n",
    "\n",
    "df_xml.to_xml(\n",
    "    OUT_DIR / \"results.xml\",\n",
    "    index=False,\n",
    "    root_name=\"papers\",\n",
    "    row_name=\"paper\",\n",
    "    parser=\"etree\",\n",
    "    xml_declaration=True,\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "# --- 4) Parquet ---\n",
    "df.to_parquet(OUT_DIR / \"results.parquet\", index=False)\n",
    "\n",
    "print(\"Spremljeno u out/: results.csv, results.json, results.xml, results.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
